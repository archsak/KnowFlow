Stylometry is the application of the study of linguistic style, usually to written language.Argamon, Shlomo, Kevin Burns, and Shlomo Dubnov, eds. The structure of style: algorithmic approaches to understanding manner and meaning. Springer Science & Business Media, 2010. It has also been applied successfully to music, paintings, and chess. 

Stylometry is often used to attribute authorship to anonymous or disputed documents. It has legal as well as academic and literary applications, ranging from the question of the authorship of Shakespeare's works to forensic linguistics and has methodological similarities with the analysis of text readability.

Stylometry may be used to unmask pseudonymous or anonymous authors, or to reveal some information about the author short of a full identification.  Authors may use adversarial stylometry to resist this identification by eliminating their own stylistic characteristics without changing the meaningful content of their communications.  It can defeat analyses that do not account for its possibility, but the ultimate effectiveness of stylometry in an adversarial environment is uncertain: stylometric identification may not be reliable, but nor can non-identification be guaranteed; adversarial stylometry's practice itself may be detectable.

History
Stylometry grew out of earlier techniques of analyzing texts for evidence of authenticity, author identity, and other questions.

The modern practice of the discipline received publicity from the study of authorship problems in English Renaissance drama. Researchers and readers observed that some playwrights of the era had distinctive patterns of language preferences, and attempted to use those patterns to identify authors of uncertain or collaborative works. Early efforts were not always successful: in 1901, one researcher attempted to use John Fletcher's preference for "⁠ ⁠'em", the contractional form of "them", as a marker to distinguish between Fletcher and Philip Massinger in their collaborations—but he mistakenly employed an edition of Massinger's works in which the editor had expanded all instances of "⁠ ⁠'em" to "them".Samuel Schoenbaum, Internal evidence and Elizabethan dramatic authorship; an essay in literary history and method, p. 171.

The basics of stylometry were established by Polish philosopher Wincenty Lutosławski in Principes de stylométrie (1890). Lutosławski used this method to develop a chronology of Plato's Dialogues.

The development of computers and their capacities for analyzing large quantities of data enhanced this type of effort by orders of magnitude. The great capacity of computers for data analysis, however, did not guarantee good quality output. During the early 1960s, Rev. A. Q. Morton produced a computer analysis of the fourteen Epistles of the New Testament attributed to St. Paul, which indicated that six different authors had written that body of work. A check of his method, applied to the works of James Joyce, gave the result that Ulysses, Joyce's multi-perspective, multi-style novel, was composed by five separate individuals, none of whom apparently had any part in the crafting of Joyce's first novel, A Portrait of the Artist as a Young Man.Samuel Schoenbaum, Internal evidence and Elizabethan dramatic authorship; an essay in literary history and method, p. 196.

In time, however, and with practice, researchers and scholars have refined their methods, to yield better results. One notable early success was the resolution of disputed authorship of twelve of The Federalist Papers by Frederick Mosteller and David Wallace. 
While there are still questions concerning initial assumptions and methods (and, perhaps, always will be), few now dispute the basic premise that linguistic analysis of written texts can produce valuable information and insight. (Indeed, this was apparent even before the advent of computers: the successful application of a textual/linguistic analysis to the Fletcher canon by Cyrus Hoy and others yielded clear results during the late 1950s and early 1960s.)

Applications
Applications of stylometry include literary studies, historical studies, social studies, information retrieval, and many forensic cases and studies. Recently, long-standing debates about anonymous medieval Icelandic sagas have been advanced through its utilisation. It can also be applied to computer code and intrinsic plagiarism detection, which is to detect plagiarism based on the writing style changes within the document. Stylometry can also be used to predict whether someone is a native or non native English speaker by their typing speed.

Stylometry as a method is vulnerable to the distortion of text during revision. There is also the case of the author adopting different styles in the course of their career as was demonstrated in the case of Plato, who chose different stylistic policies such as those adopted for the early and middle dialogues addressing the Socratic problem.

Features

Textual features of interest for authorship attribution are on the one hand computing occurrences of idiosyncratic expressions or constructions (e.g. checking for how the author uses interpunction or how often the author uses agentless passive constructions) and on the other hand similar to those used for readability analysis such as measures of lexical variation and syntactic variation.
Since authors often have preferences for certain topics, research experiments in authorship attribution mostly remove content words such as nouns, adjectives, and verbs from the feature set, only retaining structural elements of the text to avoid overfitting their models to topic rather than author characteristics.
Stylistic features are often computed as averages over a text or over the entire collected works of an author, yielding measures such as average word length or average sentence length. This enables a model to identify authors who have a clear preference for wordy or terse sentences but hides variation: an author with a mix of long and short sentences will have the same average as an author with consistent mid-length sentences. To capture such variation, some experiments use sequences or patterns over observations rather than average observed frequencies, noting e.g. that an author shows a preference for a certain stress or emphasis pattern,
or that an author tends to follow a sequence of long sentences with a short one.

One of the first approaches to authorship identification, by Mendenhall, can be said to aggregate its observations without averaging them.

More recent authorship attribution models use vector space models to automatically capture what is specific to an author's style, but they also rely on judicious feature engineering for the same reasons as more traditional models.

Adversarial stylometry

Adversarial stylometry is the practice of altering writing style to reduce the potential for stylometry to discover the author's identity or their characteristics. This task is also known as authorship obfuscation or authorship anonymisation. Stylometry poses a significant privacy challenge in its ability to unmask anonymous authors or to link pseudonyms to an author's other identities, which, for example, creates difficulties for whistleblowers, activists, and hoaxers and fraudsters. The privacy risk is expected to grow as machine learning techniques and text corpora develop.

All adversarial stylometry shares the core idea of faithfully paraphrasing the source text so that the meaning is unchanged but the stylistic signals are obscured. Such a faithful paraphrase is an adversarial example for a stylometric classifier. Several broad approaches to this exist, with some overlap: imitation, substituting the author's own style for another's; translation, applying machine translation with the hope that this eliminates characteristic style in the source text; and obfuscation, deliberately modifying a text's style to make it not resemble the author's own.

Manually obscuring style is possible, but laborious; in some circumstances, it is preferable or necessary. Automated tooling, either semi- or fully-automatic, could assist an author. How best to perform the task and the design of such tools is an open research question. While some approaches have been shown to be able to defeat particular stylometric analyses, particularly those that do not account for the potential of adversariality, establishing safety in the face of unknown analyses is an issue. Ensuring the faithfulness of the paraphrase is a critical challenge for automated tools.

It is uncertain if the practice of adversarial stylometry is detectable in itself. Some studies have found that particular methods produced signals in the output text, but a stylometrist who is uncertain of what methods may have been used may not be able to reliably detect them.

Current research

Modern stylometry uses computers for statistical analysis, and artificial intelligence and access to the growing corpus of texts available via the Internet.Argamon, Shlomo, Jussi Karlgren, and James G. Shanahan. Stylistic analysis of text for information access. Papers from the workshop held in conjunction with the
 28th Annual International ACM Conference on Research and
 Development in Information Retrieval, August 13–19, 2005,
 Salvador, Bahia, Brazil. Swedish institute of computer science, 2005. Software systems such as Signature (freeware produced by Peter Millican of Oxford University), JGAAP (the Java Graphical Authorship Attribution Program—freeware produced by Dr Patrick Juola of Duquesne University), stylo (an open-source R package for a variety of stylometric analyses, including authorship attribution, developed by Maciej Eder, Jan Rybicki and Mike Kestemont) and Stylene for Dutch (online freeware by Prof Walter Daelemans of University of Antwerp and Dr Véronique Hoste of University of Ghent) make its use increasingly practicable, even for the non-expert.

Academic venues and events

Stylometric methods are used for several academic topics, as an application of linguistics, lexicography, or literary study, in conjunction with natural language processing and machine learning, and applied to plagiarism detection, authorship analysis, or information retrieval. 

Forensic linguistics
The International Association of Forensic Linguists (IAFL) organises the Biennial Conference of the International Association of Forensic Linguists (13th edition in 2016 in Porto) and publishes The International Journal of Speech, Language and the Law with forensic stylistics as one of its central topics.

AAAI
The Association for the Advancement of Artificial Intelligence (AAAI) has hosted several events on subjective and stylistic analysis of text.Yan Qu, James G. Shanahan, and Janyce Wiebe. "Exploring attitude and affect in text: Theories and applications." AAAI Spring Symposium Technical report SS-04-07. AAAI Press, Menlo Park, CA. 2004.Jussi Karlgren, Björn Gambäck, and Pentti Kanerva. "Acquiring (and Using) Linguistic (and World) Knowledge for Information Access." (2002). AAAI Spring Symposium. Technical report SS-02-09. AAAI Press, Menlo Park, CA. 2002.Shlomo Argamon, Shlomo Dubnov, and Julie Jupp. "Style and Meaning in Language, Art, Music, and Design" (2004). AAAI Fall Symposium. Technical report FS-04-07.

PAN
PAN workshops (originally, plagiarism analysis, authorship identification, and near-duplicate detection, later more generally workshop on uncovering plagiarism, authorship, and social software misuse) organised since 2007 mainly in conjunction with information access conferences such as ACM SIGIR, FIRE, and CLEF. PAN formulates shared challenge tasks for plagiarism detection,Potthast, Martin, Benno Stein, Alberto Barrón-Cedeño, and Paolo Rosso. "An evaluation framework for plagiarism detection." In Proceedings of the 23rd international conference on computational linguistics: Posters, pp. 997–1005. Association for Computational Linguistics, 2010. authorship identification,Stamatatos, Efstathios, Walter Daelemans, Ben Verhoeven, Patrick Juola, Aurelio López-López, Martin Potthast, and Benno Stein. "Overview of the Author Identification Task at PAN 2014." In CLEF (Working Notes), pp. 877–897. 2014. author gender identification,Rangel, Francisco, Paolo Rosso, Martin Potthast, and Benno Stein. "Overview of the 5th author profiling task at pan 2017: Gender and language variety identification in twitter." Working Notes Papers of the CLEF (2017). author profiling,Rangel Pardo, Francisco Manuel, Fabio Celli, Paolo Rosso, Martin Potthast, Benno Stein, and Walter Daelemans. "Overview of the 3rd Author Profiling Task at PAN 2015." In CLEF 2015 Evaluation Labs and Workshop Working Notes Papers, pp. 1–8. 2015. vandalism detection,Potthast, Martin, Benno Stein, and Teresa Holfeld. "Overview of the 1st International Competition on Wikipedia Vandalism Detection." In CLEF (Notebook Papers/LABs/Workshops). 2010. and other related text analysis tasks, many of which hinge on stylometry.

Case studies of interest
 In 1439, Lorenzo Valla showed that the Donation of Constantine was a forgery, an argument based partly on a comparison of the Latin with that used in authentic 4th-century documents.
 In 1952, the Swedish priest Dick Helander was elected bishop of Strängnäs. The campaign was competitive and Helander was accused of writing a series of a hundred-some anonymous libelous letters about other candidates to the electorate of the bishopric of Strängnäs. Helander was first convicted of writing the letters and lost his position as bishop but later partially exonerated. The letters were studied using a number of stylometric measures (and also typewriter characteristics) and the various court cases and further examinations, many contracted by Helander himself during the years until his death in 1978, discussed stylometric method and its value as evidence in some detail.Text processing text analysis and generation – text typology and attribution. Proceedings of Nobel symposium 51. Edited by Sture Allén. Stockholm: Almqvist & Wiksell international 1982. Data linguistica, 16. Nobel symposium, 51. 
 In 1975, after Ronald Reagan had served as governor of California, he began giving weekly radio commentaries syndicated to hundreds of stations. After his personal notes were made public on his 90th birthday in 2001, a study used stylostatistical methods to determine which of those talks were written by him and which were written by various aides. 
 In 1996, the stylometric analysis of the controversial, pseudonymously authored book Primary Colors, performed by Vassar College professor Donald FosterAuthor Unknown by Gavin McNett Salon November 2, 2000 brought the topic to the attention of a wider audience after correctly identifying the author as Joe Klein. (This case was resolved only after a handwriting analysis confirmed the authorship.)
 In 1996, stylometric methods were used to compare the Unabomber Manifesto with letters written by one of the suspects, Theodore Kaczynski, which resulted in Kaczynski's apprehension and later conviction. 
 In April 2015, researchers using stylometry techniques identified a play, Double Falsehood, as being the work of William Shakespeare. Researchers analyzed 54 plays by Shakespeare and John Fletcher, and compared average sentence length, studied the use of unusual words and quantified the complexity and psychological valence of their language.
 In 2016, MacDonald P. Jackson, Emeritus Professor of English at the University of Auckland, New Zealand and a Fellow of the Royal Society of New Zealand, who had spent his entire academic career analyzing authorship attribution, wrote a book titled Who Wrote "The Night Before Christmas"?: Analyzing the Clement Clarke Moore Vs. Henry Livingston Question, in which he evaluates the opposing arguments and, for the first time, uses the author-attribution techniques of modern computational stylistics to examine the long-standing controversy. Jackson employs a range of tests and introduces a new one, statistical analysis of phonemes; he concludes that Livingston is the true author of the classic work.
In 2017, Simon Fuller and James O'Sullivan published a study claiming that bestselling author James Patterson does not do any writing in his apparently co-authored novels. According to O'Sullivan, his collaboration with former U.S. president Bill Clinton, The President is Missing, is an exception to this rule.
 In 2017, a group of linguists, computer scientists, and scholars analysed the authorship of Elena Ferrante.  Based on a corpus created at University of Padua containing 150 novels written by 40 authors, they analyzed Ferrante's style based on seven of her novels.  They were able to compare her writing style with 39 other novelists using, for example, stylo. The conclusion was the same for all of them: Domenico Starnone is the secret author of Elena Ferrante.
 In 2018, Mark Glickman, a senior lecturer in statistics at Harvard University, worked with Ryan Song, a former statistics student at Harvard, and Jason Brown, a professor at Dalhousie University in Nova Scotia, applying stylometry to find that, most likely, The Beatles' song "In My Life" was composed by John Lennon, but with a 50% chance that Paul McCartney wrote the middle eight.Reuell, Peter: "You say John, I say Paul. But what does stylometry say?" 
In 2019, the ETSO project: Stylometry applied to the Spanish Golden Age Theater,The ETSO project. directed by  and Germán Vega García-Luengos (University of Valladolid) managed to gather 3000 plays of the Spanish Golden Age. After applying stylometrical analysis, the attribution of Mujeres y criados to Lope de Vega was ratified, and an authorship problem was detected in La monja alférez, a play attributed to Pérez de Montalbán which, thanks to these analyzes and through historical and philology research, was eventually attributed to Juan Ruiz de Alarcón. In 2023, the same project found Lope de Vega as the author of La francesa Laura (The Frenchwoman Laura), despite the manuscript was written years after his death. The comedy was classified as a late work of Lope de Vega and dated from 1628 to 1630, as its flattering treatment of France could be attributed to the momentary good relationship between Spain and France during the Thirty Years' War, having England as a common enemy. In this analysis, the 500 most frequent words of the text under investigation are compared with the 500 of the rest of the works. In the case of La francesa Laura, the finding detected that the 100 works with which it was closest were almost all by Lope de Vega. Machine learning methods, such as support vector machine analysis, were also conducted with a large range of parameters. The traditional philological analysis on the authorship of works has confirmed the investigations of stylometry and artificial intelligence.
In 2020, Rachel McCarthy and James O'Sullivan argued  that Emily Brontë is the true author of Wuthering Heights, ending speculation by some critics that the novel might have been written by one of her siblings, specifically either Branwell or Charlotte.
In 2020, Hartmut Ilsemann used Rolling Delta and Rolling Classify from the R Stylo program suite to show that the Marlowe corpus is stylistically inhomogeneous, and that the author of the two Tamburlaines was hardly present in the remaining official corpus of Marlowe.Ilsemann, Harmut (2020) "Phantom Marlowe: Paradigmenwechsel in Autorschaftsbestimmungen des englischen Renaissancedramas". Düren: Shaker, ISBN 978-3-8440-7412-3
 In 2022, the Italian scholars Simone Rebora and Massimo Salgaro showed, using John F. Burrows' "Delta distance" method, that Felix Salten is the most probable author of the anonymous novel Josefine Mutzenbacher from 1906, the final pages excluded.
 In 2023, the Swedish journalist Lapo Lappin claimed that two crime novels by the Swedish author Camilla Läckberg may be the work of a ghost writer, presumably her editor Pascal Engman. This claim was first denied by the author and her spokesperson,AI avslöjar: Läckberg har antagligen spökskrivare – skjuter ned anklagelserna. Hufvudstadsbladet, 27 September 2023 (in Swedish). but later Läckberg admitted that she and Pascal Engman work very closely together and he edits her texts.

Data and methods
Since stylometry has both descriptive use cases, used to characterise the content of a collection, and identificatory use cases, e.g. identifying authors or categories of texts, the methods used to analyse the data and features above range from those built to classify items into sets or to distribute items in a space of feature variation. Most methods are statistical in nature, such as cluster analysis and discriminant analysis, are typically based on philological data and features, and are fruitful application domains for modern machine learning methods.

Whereas in the past, stylometry emphasized the rarest or most striking elements of a text, contemporary techniques can isolate identifying patterns even in common parts of speech. Most systems are based on lexical statistics, i.e. using the frequencies of words and terms in the text to characterise the text (or its author). In this context, unlike for information retrieval, the observed occurrence patterns of the most common words are more interesting than the topical terms which are less frequent.Biber, Douglas. Variation across speech and writing. Cambridge University Press, 1991.

The primary stylometric method is the writer invariant: a property held in common by all texts, or at least all texts long enough to admit of analysis yielding statistically significant results, written by a given author. An example of a writer invariant is frequency of function words used by the writer.

In one such method, the text is analyzed to find the 50 most common words. The text is then divided into 5,000 word chunks and each of the chunks is analyzed to find the frequency of those 50 words in that chunk. This generates a unique 50-number identifier for each chunk. These numbers place each chunk of text into a point in a 50-dimensional space. This 50-dimensional space is flattened into a plane using principal components analysis (PCA). This results in a display of points that correspond to an author's style. If two literary works are placed on the same plane, the resulting pattern may show if both works were by the same author or different authors.

Gaussian statistics
Stylometric data are distributed according to the Zipf–Mandelbrot law. The distribution is extremely spiky and leptokurtic, the reason why researchers could not use statistics to solve e.g. authorship attribution problems. Nevertheless, usage of Gaussian statistics is perfectly possible by applying data transformation.Van Droogenbroeck F. J., "An essential rephrasing of the Zipf-Mandelbrot law to solve authorship attribution applications by Gaussian statistics" (2019).

Neural networks
Neural networks, a special case of statistical machine learning methods, have been used to analyze authorship of texts. Texts of undisputed authorship are used to train a neural network by processes such as backpropagation, such that training error is calculated and used to update the process to increase accuracy. Through a process akin to non-linear regression, the network gains the ability to generalize its recognition ability to new texts to which it has not yet been exposed, classifying them to a stated degree of confidence. Such techniques were applied to the long-standing claims of collaboration of Shakespeare with his contemporaries John Fletcher and Christopher Marlowe, and confirmed the opinion, based on more conventional scholarship, that such collaboration had indeed occurred.
 
A 1999 study showed that a neural network program reached 70% accuracy in determining the authorship of poems it had not yet analyzed. This study from Vrije Universiteit examined identification of poems by three Dutch authors using only letter sequences such as "den".

A study used deep belief networks (DBN) for authorship verification model applicable for continuous authentication (CA).

One problem with this method of analysis is that the network can become biased based on its training set, possibly selecting authors the network has analyzed more often.

Genetic algorithms
The genetic algorithm is another machine learning technique used for stylometry. This involves a method that starts with a set of rules. An example rule might be, "If but appears more than 1.7 times in every thousand words, then the text is author X". The program is presented with text and uses the rules to determine authorship. The rules are tested against a set of known texts and each rule is given a fitness score. The 50 rules with the lowest scores are not used. The remaining 50 rules are given small changes and 50 new rules are introduced. This is repeated until the evolved rules attribute the texts correctly.

Rare pairs
One method for identifying style is termed "rare pairs" and relies upon individual habits of collocation. The use of certain words may, for a particular author, be associated idiosyncratically with the use of other, predictable words.

Authorship attribution in instant messaging
The diffusion of the internet has shifted the authorship attribution attention towards online texts (web pages, blogs, etc.) electronic messages (e-mails, tweets, posts, etc.), and other types of written information that are far shorter than an average book, much less formal and more diverse in terms of expressive elements such as colors, layout, fonts, graphics, emoticons, etc. Efforts to take into account such aspects at the level of both structure and syntax were reported in. In addition, content-specific and idiosyncratic cues (e.g., topic models and grammar checking tools) were introduced to unveil deliberate stylistic choices.

Standard stylometric features have been employed to categorize the content of a chat by instant messaging, or the behavior of the participants, but attempts of identifying chat participants are still few and early. Furthermore, the similarity between spoken conversations and chat interactions has been neglected while being a major difference between chat data and any other type of written information.